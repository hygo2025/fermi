# Otimiza√ß√£o GPU - Guia Completo

## üöÄ Configura√ß√µes Otimizadas Aplicadas

### Mudan√ßas nos Configs (todos os modelos)

**ANTES:**
```yaml
train_batch_size: 512
eval_batch_size: 512
hidden_size: 100
embedding_size: 100
```

**DEPOIS:**
```yaml
train_batch_size: 4096    # 8x maior!
eval_batch_size: 4096     # 8x maior!
hidden_size: 256          # 2.5x maior
embedding_size: 256       # 2.5x maior
```

**Impacto Esperado:**
- ‚ö° Treino 4-6x mais r√°pido
- üéØ Modelos mais expressivos
- üíæ Uso de VRAM: ~6-8 GB por experimento
- ‚è±Ô∏è Tempo total: ~6-8h ‚Üí **1-2 horas!**

### Backup dos Configs Originais

Os configs originais foram salvos em:
```
src/configs/neural/*.yaml.backup
```

Para reverter:
```bash
cd src/configs/neural
for f in *.backup; do mv "$f" "${f%.backup}"; done
```

## Op√ß√µes de Execu√ß√£o

### Op√ß√£o 1: Single Thread (Simples)

```bash
# Um experimento por vez, mas muito mais r√°pido
python src/run_experiments.py --models GRU4Rec --slices 1

# Tempo: ~30 segundos (vs 2-3 min antes)
```

### Op√ß√£o 2: Paralelo - M√∫ltiplos Slices (RECOMENDADO)

```bash
# Rodar 3 slices ao mesmo tempo
./scripts/run_parallel.sh GRU4Rec "1 2 3"

# Uso de GPU: ~18-20 GB
# Tempo: ~1 minuto para 3 slices!
```

### Op√ß√£o 3: Paralelo - M√∫ltiplos Modelos

```bash
# Terminal 1
python src/run_experiments.py --models GRU4Rec --slices 1 &

# Terminal 2
python src/run_experiments.py --models NARM --slices 1 &

# Terminal 3
python src/run_experiments.py --models STAMP --slices 1 &

# Aguardar todos
wait
```

## Uso de GPU Esperado

### Com Batch Size 4096

```
Single experiment:
‚îú‚îÄ GPU Memory: ~6-8 GB
‚îú‚îÄ GPU Util: 90-100%
‚îî‚îÄ Temp: ~65-70¬∞C

3 experiments parallel:
‚îú‚îÄ GPU Memory: ~18-22 GB
‚îú‚îÄ GPU Util: 100%
‚îî‚îÄ Temp: ~75-80¬∞C (OK, < 85¬∞C)
```

## Monitoramento

### GPU Monitor

```bash
# Terminal separado
watch -n 1 nvidia-smi

# Ou use o script customizado
./scripts/monitor_gpu.sh
```

### Logs dos Experimentos Paralelos

```bash
# Ver todos os logs ao mesmo tempo
tail -f results/logs/*_parallel.log

# Ver log espec√≠fico
tail -f results/logs/GRU4Rec_slice1_parallel.log
```

## Comandos R√°pidos

```bash
# Teste r√°pido otimizado (1 slice)
python src/run_experiments.py --models GRU4Rec --slices 1
# Tempo: ~30 segundos

# Paralelo - 3 slices
./scripts/run_parallel.sh GRU4Rec "1 2 3"
# Tempo: ~1 minuto

# Todos os 5 slices em paralelo (usa ~100% GPU)
./scripts/run_parallel.sh GRU4Rec "1 2 3 4 5"
# Tempo: ~2 minutos
# ‚ö†Ô∏è  Pode ficar apertado na VRAM, monitorar nvidia-smi

# Experimento completo otimizado
make run-all
# Tempo: ~1-2 horas (vs 6-8h antes!)
```

## Troubleshooting

### Out of Memory (OOM)

Se ver erro `CUDA out of memory`:

**Solu√ß√£o 1:** Reduzir batch size
```bash
# Editar configs
vim src/configs/neural/gru4rec.yaml

# Mudar para:
train_batch_size: 2048  # em vez de 4096
```

**Solu√ß√£o 2:** Menos slices em paralelo
```bash
# Em vez de 5, rodar 3 por vez
./scripts/run_parallel.sh GRU4Rec "1 2 3"
# Depois:
./scripts/run_parallel.sh GRU4Rec "4 5"
```

### Processos Travados

```bash
# Listar processos Python
ps aux | grep run_experiments

# Matar todos
pkill -f run_experiments.py

# Ou matar por PID
kill -9 <PID>
```

### GPU n√£o em 100%

Se GPU util < 80%:
- ‚úÖ Batch size pode estar pequeno ainda
- ‚úÖ Aumentar para 8192
- ‚úÖ Ou rodar mais slices em paralelo

## Compara√ß√£o de Performance

### Antes (Configs Originais)

| Experimento | Batch Size | Tempo |
|-------------|------------|-------|
| 1 slice | 512 | ~2-3 min |
| 5 slices | 512 | ~10-15 min |
| 20 experimentos | 512 | ~6-8 horas |

### Depois (Configs Otimizados)

| Experimento | Batch Size | Tempo |
|-------------|------------|-------|
| 1 slice | 4096 | ~30 seg |
| 5 slices (paralelo) | 4096 | ~2 min |
| 20 experimentos | 4096 | **~1-2 horas** |

**Speedup: 4-6x** üöÄ

## Restaurar Configs Originais

Se quiser voltar aos configs conservadores:

```bash
cd src/configs/neural
for f in *.backup; do 
    mv "$f" "${f%.backup}"
done
```

## Teste Recomendado Agora

```bash
# 1. Teste r√°pido (validar que funciona)
python src/run_experiments.py --models GRU4Rec --slices 1

# 2. Se funcionou, paralelo com 3 slices
./scripts/run_parallel.sh GRU4Rec "1 2 3"

# 3. Se ainda OK, rodar tudo!
make run-all
```

**Aproveite a RTX 4090!** üí™
