model: NARM

embedding_size: 64
hidden_size: 64
n_layers: 1

dropout_probs: [0.25, 0.5]

loss_type: 'CE'
learning_rate: 0.001