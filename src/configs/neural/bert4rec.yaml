model: BERT4Rec

n_layers: 2
n_heads: 2
hidden_size: 64
inner_size: 128

train_batch_size: 1024
eval_batch_size: 2048
learning_rate: 0.001

mask_ratio: 0.2

hidden_dropout_prob: 0.3
attn_dropout_prob: 0.3
loss_type: 'CE'

# BERT4Rec usa masking - n√£o precisa de negative sampling
train_neg_sample_args: ~

clip_grad_norm:
  max_norm: 5.0

transform: ~