"""
Análise qualitativa de recomendações de modelos sequenciais.
"""

import argparse
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Backend sem display para ambientes SSH
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys
import traceback
from typing import Dict, List, Any

# Adicionar diretório do projeto ao PATH
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.exploration.model_explorer import ModelExplorer
from src.utils.similarity_calc import PropertySimilarityCalculator

# Configurar estilo dos gráficos
plt.style.use('ggplot')
sns.set_palette("husl")

# Pesos para similaridade (baseado em importância de negócio)
SIMILARITY_WEIGHTS = {
    'price': 3.0,
    'bedrooms': 2.0,
    'bathrooms': 1.5,
    'usable_areas': 2.0,
    'parking_spaces': 1.0,
    'suites': 1.0,
    'neighborhood': 5.0,  # Localização muito importante
    'city': 3.0
}


def print_section_header(title: str, char: str = "=", width: int = 100):
    print("\n" + char * width)
    print(f" {title}")
    print(char * width)


def analyze_single_session(
    explorer: ModelExplorer,
    session_items: List[int],
    session_id: str = "Unknown",
    top_k: int = 10
) -> Dict[str, Any]:
    print(f"\nAnalisando Sessao: {session_id}")
    print(f"  Itens: {session_items}")
    
    result = {
        'session_id': session_id,
        'session_size': len(session_items)
    }
    
    # Caracterizar sessão
    if explorer.item_features is not None:
        sess_df = explorer.item_features[
            explorer.item_features['listing_id'].isin(session_items)
        ]
        
        if len(sess_df) > 0:
            print(f"\n  {len(sess_df)} itens encontrados nas features")
            
            # Preço
            if 'price' in sess_df.columns:
                prices = sess_df['price'].dropna()
                if len(prices) > 0:
                    avg_price = prices.mean()
                    result['session_avg_price'] = avg_price
                    print(f"  Preco medio: R$ {avg_price:,.0f} (min: {prices.min():,.0f}, max: {prices.max():,.0f})")
                    
                    if avg_price > 1000000:
                        profile = "LUXO"
                    elif avg_price < 300000:
                        profile = "ECONOMICO"
                    else:
                        profile = "PADRAO"
                    result['profile'] = profile
            
            # Localização
            if 'city' in sess_df.columns:
                cities = sess_df['city'].value_counts().to_dict()
                result['session_cities'] = cities
                print(f"  Cidade: {list(cities.keys())[0] if cities else 'N/A'}")
            
            if 'neighborhood' in sess_df.columns:
                neighborhoods = sess_df['neighborhood'].value_counts().to_dict()
                result['session_neighborhoods'] = neighborhoods
                top_neighborhood = list(neighborhoods.keys())[0] if neighborhoods else 'N/A'
                print(f"  Bairro: {top_neighborhood}")
            
            # Características físicas
            if 'bedrooms' in sess_df.columns:
                bedrooms = sess_df['bedrooms'].dropna()
                if len(bedrooms) > 0:
                    result['session_bedrooms_med'] = bedrooms.median()
                    print(f"  Quartos: {bedrooms.median():.0f} (media)")
            
            if 'bathrooms' in sess_df.columns:
                bathrooms = sess_df['bathrooms'].dropna()
                if len(bathrooms) > 0:
                    result['session_bathrooms_med'] = bathrooms.median()
                    print(f"  Banheiros: {bathrooms.median():.0f} (media)")
            
            if 'suites' in sess_df.columns:
                suites = sess_df['suites'].dropna()
                if len(suites) > 0:
                    result['session_suites_med'] = suites.median()
                    print(f"  Suites: {suites.median():.0f} (media)")
            
            if 'parking_spaces' in sess_df.columns:
                parking = sess_df['parking_spaces'].dropna()
                if len(parking) > 0:
                    result['session_parking_med'] = parking.median()
                    print(f"  Vagas: {parking.median():.0f} (media)")
            
            if 'usable_areas' in sess_df.columns:
                areas = sess_df['usable_areas'].dropna()
                if len(areas) > 0:
                    result['session_area_med'] = areas.median()
                    print(f"  Area util: {areas.median():.0f}m2 (mediana)")
            
            # Tipo
            if 'unit_type' in sess_df.columns:
                unit_types = sess_df['unit_type'].value_counts().to_dict()
                result['session_unit_types'] = unit_types
                top_type = list(unit_types.keys())[0] if unit_types else 'N/A'
                print(f"  Tipo: {top_type}")
    
    print(f"\n  Gerando Top-{top_k} recomendacoes...")
    try:
        recs = explorer.recommend_for_session(session_items, top_k=top_k)
        
        if not recs or len(recs) == 0:
            print("  AVISO: Nenhuma recomendacao gerada")
            result['error'] = 'no_recommendations'
            return result
        
        result['recommendations'] = recs
        print(f"  Recomendacoes: {recs}")
        
        # Comparar características
        if explorer.item_features is not None and len(sess_df) > 0:
            rec_df = explorer.item_features[
                explorer.item_features['listing_id'].isin(recs)
            ]
            
            if len(rec_df) > 0:
                print(f"\n  Comparando caracteristicas ({len(rec_df)} recomendacoes)...")
                
                # Preço
                if 'price' in sess_df.columns and 'price' in rec_df.columns:
                    sess_prices = sess_df['price'].dropna()
                    rec_prices = rec_df['price'].dropna()
                    
                    if len(sess_prices) > 0 and len(rec_prices) > 0:
                        sess_price = sess_prices.mean()
                        rec_price = rec_prices.mean()
                        diff_pct = ((rec_price - sess_price) / sess_price * 100)
                        
                        result['rec_avg_price'] = rec_price
                        result['price_diff_pct'] = diff_pct
                        
                        print(f"  Preco: sessao R$ {sess_price:,.0f} vs recs R$ {rec_price:,.0f} ({diff_pct:+.1f}%)", end="")
                        
                        if abs(diff_pct) < 20:
                            print(" [SIMILAR]")
                            result['price_match'] = 'SIMILAR'
                        elif abs(diff_pct) < 50:
                            print(" [MODERADO]")
                            result['price_match'] = 'MODERADO'
                        else:
                            print(" [GRANDE]")
                            result['price_match'] = 'GRANDE'
                
                # Bairro (mais específico que cidade)
                if 'neighborhood' in sess_df.columns and 'neighborhood' in rec_df.columns:
                    sess_neigh = set(sess_df['neighborhood'].dropna())
                    rec_neigh = set(rec_df['neighborhood'].dropna())
                    overlap_neigh = sess_neigh & rec_neigh
                    
                    if len(overlap_neigh) > 0:
                        print(f"  Bairro: overlap {overlap_neigh} [SIM]")
                        result['neighborhood_match'] = 'SIM'
                    else:
                        print(f"  Bairro: sem overlap (sessao: {list(sess_neigh)[:2]}, recs: {list(rec_neigh)[:2]}) [NAO]")
                        result['neighborhood_match'] = 'NAO'
                
                # Cidade (fallback se bairro não tem overlap)
                if 'city' in sess_df.columns and 'city' in rec_df.columns:
                    sess_cities = set(sess_df['city'].dropna())
                    rec_cities = set(rec_df['city'].dropna())
                    overlap = sess_cities & rec_cities
                    
                    if len(overlap) > 0:
                        print(f"  Cidade: overlap {overlap} [SIM]")
                        result['city_match'] = 'SIM'
                    else:
                        print(f"  Cidade: sem overlap [NAO]")
                        result['city_match'] = 'NAO'
                
                # Quartos
                if 'bedrooms' in sess_df.columns and 'bedrooms' in rec_df.columns:
                    sess_bedrooms = sess_df['bedrooms'].dropna().median()
                    rec_bedrooms = rec_df['bedrooms'].dropna().median()
                    
                    result['session_bedrooms_median'] = sess_bedrooms
                    result['rec_bedrooms_median'] = rec_bedrooms
                    
                    diff = abs(sess_bedrooms - rec_bedrooms)
                    print(f"  Quartos: sessao {sess_bedrooms:.0f} vs recs {rec_bedrooms:.0f}", end="")
                    
                    if diff == 0:
                        print(" [IGUAL]")
                        result['bedrooms_match'] = 'IGUAL'
                    elif diff <= 1:
                        print(f" [PROXIMO]")
                        result['bedrooms_match'] = 'PROXIMO'
                    else:
                        print(f" [DIFERENTE]")
                        result['bedrooms_match'] = 'DIFERENTE'
                
                # Banheiros
                if 'bathrooms' in sess_df.columns and 'bathrooms' in rec_df.columns:
                    sess_bath = sess_df['bathrooms'].dropna().median()
                    rec_bath = rec_df['bathrooms'].dropna().median()
                    
                    diff = abs(sess_bath - rec_bath)
                    status = 'IGUAL' if diff == 0 else ('PROXIMO' if diff <= 1 else 'DIFERENTE')
                    print(f"  Banheiros: sessao {sess_bath:.0f} vs recs {rec_bath:.0f} [{status}]")
                    result['bathrooms_match'] = status
                
                # Vagas
                if 'parking_spaces' in sess_df.columns and 'parking_spaces' in rec_df.columns:
                    sess_park = sess_df['parking_spaces'].dropna().median()
                    rec_park = rec_df['parking_spaces'].dropna().median()
                    
                    diff = abs(sess_park - rec_park)
                    status = 'IGUAL' if diff == 0 else ('PROXIMO' if diff <= 1 else 'DIFERENTE')
                    print(f"  Vagas: sessao {sess_park:.0f} vs recs {rec_park:.0f} [{status}]")
                    result['parking_match'] = status
                
                # Área útil
                if 'usable_areas' in sess_df.columns and 'usable_areas' in rec_df.columns:
                    sess_area = sess_df['usable_areas'].dropna().median()
                    rec_area = rec_df['usable_areas'].dropna().median()
                    
                    if sess_area > 0:
                        diff_pct = abs((rec_area - sess_area) / sess_area * 100)
                        status = 'SIMILAR' if diff_pct < 20 else ('MODERADO' if diff_pct < 50 else 'GRANDE')
                        print(f"  Area: sessao {sess_area:.0f}m2 vs recs {rec_area:.0f}m2 ({diff_pct:.1f}%) [{status}]")
                        result['area_match'] = status
                
                # Tipo de unidade
                if 'unit_type' in sess_df.columns and 'unit_type' in rec_df.columns:
                    sess_types = set(sess_df['unit_type'].dropna())
                    rec_types = set(rec_df['unit_type'].dropna())
                    overlap_type = sess_types & rec_types
                    
                    if len(overlap_type) > 0:
                        print(f"  Tipo: overlap {overlap_type} [SIM]")
                        result['unit_type_match'] = 'SIM'
                    else:
                        print(f"  Tipo: sem overlap [NAO]")
                        result['unit_type_match'] = 'NAO'
                
                # Calcular similaridade ponderada
                print(f"\n  Calculando similaridade ponderada...")
                try:
                    # Preparar dados para PropertySimilarityCalculator
                    all_items = list(set(session_items + recs))
                    items_df = explorer.item_features[
                        explorer.item_features['listing_id'].isin(all_items)
                    ].copy()
                    
                    if len(items_df) > 0:
                        # Definir features disponíveis
                        numerical_features = []
                        categorical_features = []
                        
                        for col in ['price', 'usable_areas', 'bathrooms', 'bedrooms', 'suites', 'parking_spaces']:
                            if col in items_df.columns:
                                numerical_features.append(col)
                        
                        for col in ['city', 'neighborhood']:
                            if col in items_df.columns:
                                categorical_features.append(col)
                        
                        # Criar calculador
                        calc = PropertySimilarityCalculator(
                            dataframe=items_df,
                            id_column='listing_id',
                            numerical_features=numerical_features,
                            categorical_features=categorical_features,
                            amenities_column='amenities' if 'amenities' in items_df.columns else None
                        )
                        
                        # Calcular similaridade de cada recomendação com cada item da sessão
                        similarities = []
                        for sess_item in session_items:
                            if sess_item in items_df['listing_id'].values:
                                for rec_item in recs:
                                    if rec_item in items_df['listing_id'].values:
                                        sim = calc.calculate_similarity(sess_item, rec_item, SIMILARITY_WEIGHTS)
                                        if sim is not None:
                                            similarities.append(sim)
                        
                        if similarities:
                            avg_similarity = sum(similarities) / len(similarities) * 100
                            result['avg_similarity'] = avg_similarity
                            
                            if avg_similarity >= 70:
                                status = "EXCELENTE"
                            elif avg_similarity >= 50:
                                status = "BOM"
                            elif avg_similarity >= 30:
                                status = "MODERADO"
                            else:
                                status = "RUIM"
                            
                            print(f"  Similaridade ponderada: {avg_similarity:.1f}% [{status}]")
                            result['similarity_status'] = status
                except Exception as e_sim:
                    print(f"  AVISO: Erro ao calcular similaridade: {e_sim}")
            else:
                print("  Recomendacoes sem features disponiveis")
    
    except Exception as e:
        print(f"  Erro ao gerar recomendacoes: {e}")
        result['error'] = str(e)
    
    return result


def analyze_multiple_sessions(
    explorer: ModelExplorer,
    test_df: pd.DataFrame,
    num_sessions: int = 5,
    top_k: int = 5
) -> pd.DataFrame:
    print_section_header("ANALISE DE MULTIPLAS SESSOES")
    
    valid_sessions_df = test_df.groupby('session_id:token').filter(lambda x: len(x) >= 3)
    unique_sessions = valid_sessions_df['session_id:token'].unique()
    
    print(f"\nTotal de sessoes validas no dataset: {len(unique_sessions):,}")
    print(f"Analisando {num_sessions} sessoes aleatorias...\n")
    
    # Selecionar sessões aleatoriamente
    selected_sessions = np.random.choice(
        unique_sessions,
        size=min(num_sessions, len(unique_sessions)),
        replace=False
    )
    
    results = []
    
    for i, session_id in enumerate(selected_sessions, 1):
        print_section_header(f"SESSÃO {i}/{len(selected_sessions)}: {session_id}", char="-")
        
        try:
            # Extrair itens da sessão
            session_data = test_df[
                test_df['session_id:token'] == session_id
            ].sort_values('timestamp:float')
            
            session_items = session_data['item_id:token'].tolist()[:5]
            
            if not session_items:
                print("AVISO: Sessao vazia, pulando...")
                results.append({
                    'session_id': session_id,
                    'error': 'empty_session'
                })
                continue
            
            # Analisar sessão
            result = analyze_single_session(
                explorer,
                session_items,
                session_id,
                top_k
            )
            results.append(result)
        
        except Exception as e:
            print(f"\nErro ao processar sessao: {e}")
            traceback.print_exc()
            results.append({
                'session_id': session_id,
                'error': str(e)
            })
    
    results_df = pd.DataFrame(results)
    
    print_section_header("RESUMO ESTATISTICO")
    
    # Filtrar sessões com erro para estatísticas
    if 'error' in results_df.columns:
        errors_count = results_df['error'].notna().sum()
        if errors_count > 0:
            print(f"\nAVISO: {errors_count} sessoes com erro foram ignoradas nas estatisticas")
        results_df_clean = results_df[results_df['error'].isna()].copy()
    else:
        results_df_clean = results_df.copy()
    
    if len(results_df_clean) == 0:
        print("\nERRO: Nenhuma sessao valida para analise")
        return results_df
    
    print(f"\nResultados por sessao ({len(results_df_clean)} validas):")
    display_cols = [
        'session_id', 'profile', 'avg_similarity', 'similarity_status',
        'price_match', 'neighborhood_match', 'city_match', 'bedrooms_match'
    ]
    available_cols = [col for col in display_cols if col in results_df_clean.columns]
    if available_cols:
        print(results_df_clean[available_cols].to_string(index=False))
    else:
        print(results_df_clean.to_string(index=False))
    
    # Estatísticas por métrica
    metrics = [
        ('Similaridade Ponderada', 'similarity_status'),
        ('Precos', 'price_match'),
        ('Bairro', 'neighborhood_match'),
        ('Cidade', 'city_match'),
        ('Quartos', 'bedrooms_match'),
        ('Banheiros', 'bathrooms_match'),
        ('Vagas', 'parking_match'),
        ('Area', 'area_match'),
        ('Tipo Unidade', 'unit_type_match')
    ]
    
    for label, col in metrics:
        if col in results_df_clean.columns:
            print(f"\nCompatibilidade de {label}:")
            counts = results_df_clean[col].value_counts()
            for match, count in counts.items():
                pct = (count / len(results_df_clean)) * 100
                print(f"  {match}: {count} ({pct:.1f}%)")
    
    if 'profile' in results_df_clean.columns:
        print("\nPerfis de Sessoes:")
        profile_counts = results_df_clean['profile'].value_counts()
        for profile, count in profile_counts.items():
            pct = (count / len(results_df_clean)) * 100
            print(f"  {profile}: {count} ({pct:.1f}%)")
    
    return results_df


def create_visualizations(
    explorer: ModelExplorer,
    session_items: List[int],
    top_k: int = 10,
    output_dir: Path = None,
    results_df: pd.DataFrame = None
):
    print_section_header("CRIANDO VISUALIZACOES")
    
    if explorer.item_features is None:
        print("Features nao disponiveis para visualizacao")
        return
    
    # Obter dados
    sess_df = explorer.item_features[
        explorer.item_features['listing_id'].isin(session_items)
    ]
    
    try:
        recs = explorer.recommend_for_session(session_items, top_k=top_k)
        
        if not recs or len(recs) == 0:
            print("Nenhuma recomendacao gerada, pulando visualizacoes")
            return
        
        rec_df = explorer.item_features[
            explorer.item_features['listing_id'].isin(recs)
        ]
        
        if len(sess_df) == 0 or len(rec_df) == 0:
            print("Dados insuficientes para visualizacao")
            return
    except Exception as e:
        print(f"Erro ao gerar recomendacoes para visualizacao: {e}")
        return
    
    # Criar grid 3x3 para 9 gráficos
    fig, axes = plt.subplots(3, 3, figsize=(22, 18))
    fig.suptitle('Analise Comparativa: Sessao vs Recomendacoes', 
                 fontsize=18, fontweight='bold')
    axes = axes.flatten()
    
    # 1. Gráfico de Similaridade (NOVO - mais importante no topo)
    if results_df is not None and 'avg_similarity' in results_df.columns:
        similarities = results_df['avg_similarity'].dropna()
        
        if len(similarities) > 0:
            # Histograma
            axes[0].hist(similarities, bins=15, color='green', alpha=0.7, edgecolor='black')
            
            # Linhas de threshold
            axes[0].axvline(70, color='darkgreen', linestyle='--', linewidth=2, label='Excelente (70%)')
            axes[0].axvline(50, color='orange', linestyle='--', linewidth=2, label='Bom (50%)')
            axes[0].axvline(30, color='red', linestyle='--', linewidth=2, label='Moderado (30%)')
            
            # Média
            mean_sim = similarities.mean()
            axes[0].axvline(mean_sim, color='blue', linestyle='-', linewidth=3, label=f'Media: {mean_sim:.1f}%')
            
            axes[1].set_xlabel('Similaridade Ponderada (%)', fontsize=11)
            axes[1].set_ylabel('Frequencia', fontsize=11)
            axes[0].set_title('Distribuicao de Similaridade', fontsize=13, fontweight='bold')
            axes[1].legend(fontsize=8)
            axes[6].grid(True, alpha=0.3)
    
    # 2. Histograma de preços
    if 'price' in sess_df.columns and 'price' in rec_df.columns:
        sess_prices = sess_df['price'].dropna()
        rec_prices = rec_df['price'].dropna()
        
        if len(sess_prices) > 0 and len(rec_prices) > 0:
            axes[1].hist(sess_prices, bins=10, alpha=0.6, 
                        label='Sessao', color='blue', edgecolor='black')
            axes[1].hist(rec_prices, bins=10, alpha=0.6, 
                        label='Recomendacoes', color='red', edgecolor='black')
            
            sess_mean = sess_prices.mean()
            rec_mean = rec_prices.mean()
            axes[1].axvline(sess_mean, color='blue', linestyle='--', 
                           linewidth=2, label=f'Media sessao: R$ {sess_mean:,.0f}')
            axes[1].axvline(rec_mean, color='red', linestyle='--', 
                           linewidth=2, label=f'Media recs: R$ {rec_mean:,.0f}')
            
            axes[1].set_xlabel('Preco (R$)', fontsize=11)
            axes[1].set_ylabel('Frequencia', fontsize=11)
            axes[1].set_title('Distribuicao de Precos', fontsize=13, fontweight='bold')
            axes[1].legend(fontsize=9)
            axes[1].grid(True, alpha=0.3)
        else:
            axes[1].text(0.5, 0.5, 'Dados insuficientes', ha='center', va='center', transform=axes[1].transAxes)
            axes[1].set_title('Distribuicao de Precos', fontsize=13, fontweight='bold')
    else:
        axes[1].text(0.5, 0.5, 'Dados nao disponiveis', ha='center', va='center', transform=axes[1].transAxes)
        axes[1].set_title('Distribuicao de Precos', fontsize=13, fontweight='bold')
    
    # 3. Boxplot de áreas
    area_col = 'usable_areas' if 'usable_areas' in rec_df.columns else 'total_areas'
    if area_col in sess_df.columns and area_col in rec_df.columns:
        sess_areas = sess_df[area_col].dropna()
        rec_areas = rec_df[area_col].dropna()
        
        if len(sess_areas) > 0 and len(rec_areas) > 0:
            data_to_plot = [sess_areas, rec_areas]
            bp = axes[2].boxplot(data_to_plot, tick_labels=['Sessao', 'Recomendacoes'],
                                patch_artist=True, widths=0.6)
            
            bp['boxes'][0].set_facecolor('lightblue')
            bp['boxes'][1].set_facecolor('lightcoral')
            
            axes[2].set_ylabel('Area (m2)', fontsize=11)
            axes[2].set_title('Distribuicao de Areas', fontsize=13, fontweight='bold')
            axes[6].grid(True, alpha=0.3, axis='y')
            
            sess_median = sess_areas.median()
            rec_median = rec_areas.median()
            axes[2].text(1, sess_median, f'{sess_median:.0f}m2', 
                        ha='left', va='center', fontweight='bold', fontsize=9)
            axes[2].text(2, rec_median, f'{rec_median:.0f}m2', 
                        ha='left', va='center', fontweight='bold', fontsize=9)
    
    # 3. Gráfico de barras - Quartos
    if 'bedrooms' in sess_df.columns and 'bedrooms' in rec_df.columns:
        sess_bedrooms = sess_df['bedrooms'].value_counts().sort_index()
        rec_bedrooms = rec_df['bedrooms'].value_counts().sort_index()
        
        all_bedrooms = sorted(set(sess_bedrooms.index) | set(rec_bedrooms.index))
        
        x = np.arange(len(all_bedrooms))
        width = 0.35
        
        sess_counts = [sess_bedrooms.get(b, 0) for b in all_bedrooms]
        rec_counts = [rec_bedrooms.get(b, 0) for b in all_bedrooms]
        
        axes[6].bar(x - width/2, sess_counts, width, 
                   label='Sessao', color='blue', alpha=0.7)
        axes[6].bar(x + width/2, rec_counts, width, 
                   label='Recomendacoes', color='red', alpha=0.7)
        
        axes[3].set_xlabel('Numero de Quartos', fontsize=11)
        axes[6].set_ylabel('Frequencia', fontsize=11)
        axes[2].set_title('Distribuicao de Quartos', fontsize=13, fontweight='bold')
        axes[6].set_xticks(x)
        axes[4].set_xticklabels([f'{int(b)}' for b in all_bedrooms])
        axes[6].legend(fontsize=9)
        axes[6].grid(True, alpha=0.3, axis='y')
    
    # 4. Gráfico de barras - Banheiros
    if 'bathrooms' in sess_df.columns and 'bathrooms' in rec_df.columns:
        sess_bath = sess_df['bathrooms'].value_counts().sort_index()
        rec_bath = rec_df['bathrooms'].value_counts().sort_index()
        
        all_bath = sorted(set(sess_bath.index) | set(rec_bath.index))
        
        x = np.arange(len(all_bath))
        width = 0.35
        
        sess_counts = [sess_bath.get(b, 0) for b in all_bath]
        rec_counts = [rec_bath.get(b, 0) for b in all_bath]
        
        axes[6].bar(x - width/2, sess_counts, width, 
                   label='Sessao', color='blue', alpha=0.7)
        axes[6].bar(x + width/2, rec_counts, width, 
                   label='Recomendacoes', color='red', alpha=0.7)
        
        axes[4].set_xlabel('Numero de Banheiros', fontsize=11)
        axes[6].set_ylabel('Frequencia', fontsize=11)
        axes[3].set_title('Distribuicao de Banheiros', fontsize=13, fontweight='bold')
        axes[6].set_xticks(x)
        axes[4].set_xticklabels([f'{int(b)}' for b in all_bath])
        axes[6].legend(fontsize=9)
        axes[6].grid(True, alpha=0.3, axis='y')
    
    # 5. Gráfico de barras - Vagas
    if 'parking_spaces' in sess_df.columns and 'parking_spaces' in rec_df.columns:
        sess_park = sess_df['parking_spaces'].value_counts().sort_index()
        rec_park = rec_df['parking_spaces'].value_counts().sort_index()
        
        all_park = sorted(set(sess_park.index) | set(rec_park.index))
        
        x = np.arange(len(all_park))
        width = 0.35
        
        sess_counts = [sess_park.get(p, 0) for p in all_park]
        rec_counts = [rec_park.get(p, 0) for p in all_park]
        
        axes[6].bar(x - width/2, sess_counts, width, 
                   label='Sessao', color='blue', alpha=0.7)
        axes[6].bar(x + width/2, rec_counts, width, 
                   label='Recomendacoes', color='red', alpha=0.7)
        
        axes[5].set_xlabel('Numero de Vagas', fontsize=11)
        axes[6].set_ylabel('Frequencia', fontsize=11)
        axes[4].set_title('Distribuicao de Vagas', fontsize=13, fontweight='bold')
        axes[6].set_xticks(x)
        axes[5].set_xticklabels([f'{int(p)}' for p in all_park])
        axes[6].legend(fontsize=9)
        axes[6].grid(True, alpha=0.3, axis='y')
    
    # 6. Gráfico de barras - Tipo de Unidade
    if 'unit_type' in sess_df.columns and 'unit_type' in rec_df.columns:
        sess_types = sess_df['unit_type'].value_counts()
        rec_types = rec_df['unit_type'].value_counts()
        
        all_types = sorted(set(sess_types.index) | set(rec_types.index))
        
        x = np.arange(len(all_types))
        width = 0.35
        
        sess_counts = [sess_types.get(t, 0) for t in all_types]
        rec_counts = [rec_types.get(t, 0) for t in all_types]
        
        axes[6].bar(x - width/2, sess_counts, width, 
                   label='Sessao', color='blue', alpha=0.7)
        axes[6].bar(x + width/2, rec_counts, width, 
                   label='Recomendacoes', color='red', alpha=0.7)
        
        axes[6].set_xlabel('Tipo de Unidade', fontsize=11)
        axes[6].set_ylabel('Frequencia', fontsize=11)
        axes[6].set_title('Distribuicao de Tipos', fontsize=13, fontweight='bold')
        axes[6].set_xticks(x)
        axes[6].set_xticklabels(all_types, rotation=45, ha='right')
        axes[6].legend(fontsize=9)
        axes[6].grid(True, alpha=0.3, axis='y')
    
    # 7. Gráfico de barras - Status de Similaridade
    if results_df is not None and 'similarity_status' in results_df.columns:
        status_counts = results_df['similarity_status'].value_counts()
        colors_map = {'EXCELENTE': 'darkgreen', 'BOM': 'green', 'MODERADO': 'orange', 'RUIM': 'red'}
        colors = [colors_map.get(s, 'gray') for s in status_counts.index]
        
        axes[7].bar(range(len(status_counts)), status_counts.values, color=colors, alpha=0.7, edgecolor='black')
        axes[7].set_xlabel('Status', fontsize=11)
        axes[7].set_ylabel('Numero de Sessoes', fontsize=11)
        axes[7].set_title('Distribuicao de Status', fontsize=13, fontweight='bold')
        axes[7].set_xticks(range(len(status_counts)))
        axes[7].set_xticklabels(status_counts.index, rotation=45, ha='right')
        axes[7].grid(True, alpha=0.3, axis='y')
        
        # Adicionar valores nas barras
        for i, v in enumerate(status_counts.values):
            axes[7].text(i, v, str(v), ha='center', va='bottom', fontweight='bold')
    
    # 8. Resumo de Métricas (Radar/Spider Chart ou Barras Horizontais)
    if results_df is not None:
        metrics_scores = []
        metrics_labels = []
        
        if 'price_match' in results_df.columns:
            score = (results_df['price_match'] == 'SIMILAR').sum() / len(results_df) * 100
            metrics_scores.append(score)
            metrics_labels.append('Preco')
        
        if 'neighborhood_match' in results_df.columns:
            score = (results_df['neighborhood_match'] == 'SIM').sum() / len(results_df) * 100
            metrics_scores.append(score)
            metrics_labels.append('Bairro')
        
        if 'bedrooms_match' in results_df.columns:
            score = (results_df['bedrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum() / len(results_df) * 100
            metrics_scores.append(score)
            metrics_labels.append('Quartos')
        
        if 'bathrooms_match' in results_df.columns:
            score = (results_df['bathrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum() / len(results_df) * 100
            metrics_scores.append(score)
            metrics_labels.append('Banheiros')
        
        if 'unit_type_match' in results_df.columns:
            score = (results_df['unit_type_match'] == 'SIM').sum() / len(results_df) * 100
            metrics_scores.append(score)
            metrics_labels.append('Tipo')
        
        if metrics_scores:
            y_pos = np.arange(len(metrics_labels))
            colors = ['green' if s >= 60 else 'orange' if s >= 30 else 'red' for s in metrics_scores]
            
            axes[8].barh(y_pos, metrics_scores, color=colors, alpha=0.7, edgecolor='black')
            axes[8].set_yticks(y_pos)
            axes[8].set_yticklabels(metrics_labels)
            axes[8].set_xlabel('Score (%)', fontsize=11)
            axes[8].set_title('Score por Metrica', fontsize=13, fontweight='bold')
            axes[8].set_xlim(0, 100)
            axes[8].axvline(60, color='green', linestyle='--', alpha=0.5, label='Bom (60%)')
            axes[8].axvline(30, color='orange', linestyle='--', alpha=0.5, label='Moderado (30%)')
            axes[8].legend(fontsize=8)
            axes[8].grid(True, alpha=0.3, axis='x')
            
            # Adicionar valores nas barras
            for i, v in enumerate(metrics_scores):
                axes[8].text(v + 1, i, f'{v:.1f}%', va='center', fontsize=9)
    
    plt.tight_layout()
    
    if output_dir:
        output_dir.mkdir(parents=True, exist_ok=True)
        fig_path = output_dir / 'comparative_analysis.png'
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        print(f"\nGrafico salvo em: {fig_path}")
    else:
        print("\nAVISO: output_dir nao especificado, grafico nao foi salvo")
    
    plt.close(fig)


def print_final_summary(results_df: pd.DataFrame):
    print_section_header("RESUMO FINAL")
    
    # Filtrar erros
    if 'error' in results_df.columns:
        results_df = results_df[results_df['error'].isna()].copy()
    
    if len(results_df) == 0:
        print("\nNenhuma sessao valida para gerar resumo")
        return
    
    print("\nCHECKLIST DE VALIDACAO:")
    print("  [ ] As recomendacoes tem precos similares a sessao?")
    print("  [ ] As recomendacoes sao da mesma regiao geografica?")
    print("  [ ] O numero de quartos/tamanho e compativel?")
    print("  [ ] O tipo de imovel faz sentido?")
    print("  [ ] O modelo se adapta a diferentes perfis?")
    print("  [ ] Ha diversidade nas recomendacoes?")
    
    print("\nVALIDACAO AUTOMATICA:")
    
    # Similaridade ponderada (métrica principal)
    if 'avg_similarity' in results_df.columns:
        avg_sim = results_df['avg_similarity'].mean()
        status = "BOM" if avg_sim >= 50 else ("MODERADO" if avg_sim >= 30 else "RUIM")
        print(f"  Similaridade ponderada (media): {avg_sim:.1f}% [{status}]")
        
        if 'similarity_status' in results_df.columns:
            good_count = (results_df['similarity_status'].isin(['EXCELENTE', 'BOM'])).sum()
            good_pct = good_count / len(results_df) * 100
            print(f"  Sessoes com boa similaridade: {good_pct:.1f}%")
    
    print("\n  Metricas individuais:")
    
    # Preço
    if 'price_match' in results_df.columns:
        similar_pct = (results_df['price_match'] == 'SIMILAR').sum() / len(results_df) * 100
        status = "BOM" if similar_pct >= 60 else ("MODERADO" if similar_pct >= 30 else "RUIM")
        print(f"    Precos similares: {similar_pct:.1f}% [{status}]")
    
    # Bairro (prioridade sobre cidade)
    if 'neighborhood_match' in results_df.columns:
        neigh_pct = (results_df['neighborhood_match'] == 'SIM').sum() / len(results_df) * 100
        status = "BOM" if neigh_pct >= 60 else ("MODERADO" if neigh_pct >= 30 else "RUIM")
        print(f"  Bairro compativel: {neigh_pct:.1f}% [{status}]")
    
    # Cidade (fallback)
    if 'city_match' in results_df.columns:
        city_pct = (results_df['city_match'] == 'SIM').sum() / len(results_df) * 100
        status = "BOM" if city_pct >= 60 else ("MODERADO" if city_pct >= 30 else "RUIM")
        print(f"  Cidade compativel: {city_pct:.1f}% [{status}]")
    
    # Quartos
    if 'bedrooms_match' in results_df.columns:
        bedrooms_ok = (results_df['bedrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum()
        bedrooms_pct = bedrooms_ok / len(results_df) * 100
        status = "BOM" if bedrooms_pct >= 60 else ("MODERADO" if bedrooms_pct >= 30 else "RUIM")
        print(f"  Quartos compativeis: {bedrooms_pct:.1f}% [{status}]")
    
    # Banheiros
    if 'bathrooms_match' in results_df.columns:
        bath_ok = (results_df['bathrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum()
        bath_pct = bath_ok / len(results_df) * 100
        status = "BOM" if bath_pct >= 60 else ("MODERADO" if bath_pct >= 30 else "RUIM")
        print(f"  Banheiros compativeis: {bath_pct:.1f}% [{status}]")
    
    # Vagas
    if 'parking_match' in results_df.columns:
        parking_ok = (results_df['parking_match'].isin(['IGUAL', 'PROXIMO'])).sum()
        parking_pct = parking_ok / len(results_df) * 100
        status = "BOM" if parking_pct >= 60 else ("MODERADO" if parking_pct >= 30 else "RUIM")
        print(f"  Vagas compativeis: {parking_pct:.1f}% [{status}]")
    
    # Área
    if 'area_match' in results_df.columns:
        area_ok = (results_df['area_match'] == 'SIMILAR').sum()
        area_pct = area_ok / len(results_df) * 100
        status = "BOM" if area_pct >= 60 else ("MODERADO" if area_pct >= 30 else "RUIM")
        print(f"  Area compativel: {area_pct:.1f}% [{status}]")
    
    # Tipo de unidade
    if 'unit_type_match' in results_df.columns:
        type_pct = (results_df['unit_type_match'] == 'SIM').sum() / len(results_df) * 100
        status = "BOM" if type_pct >= 60 else ("MODERADO" if type_pct >= 30 else "RUIM")
        print(f"  Tipo de imovel compativel: {type_pct:.1f}% [{status}]")
    
    # Score geral (similaridade ponderada tem peso maior)
    if 'avg_similarity' in results_df.columns:
        similarity_score = results_df['avg_similarity'].mean()
        print(f"\n  SCORE GERAL (Similaridade Ponderada): {similarity_score:.1f}%", end="")
        if similarity_score >= 70:
            print(" [EXCELENTE - Deploy em producao]")
        elif similarity_score >= 50:
            print(" [BOM - Pronto para A/B test]")
        elif similarity_score >= 30:
            print(" [MODERADO - Precisa melhorar]")
        else:
            print(" [RUIM - Nao colocar em producao]")
    else:
        # Fallback: score baseado em métricas individuais
        scores = []
        if 'price_match' in results_df.columns:
            scores.append((results_df['price_match'] == 'SIMILAR').sum() / len(results_df) * 100)
        if 'neighborhood_match' in results_df.columns:
            scores.append((results_df['neighborhood_match'] == 'SIM').sum() / len(results_df) * 100)
        if 'bedrooms_match' in results_df.columns:
            scores.append((results_df['bedrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum() / len(results_df) * 100)
        if 'bathrooms_match' in results_df.columns:
            scores.append((results_df['bathrooms_match'].isin(['IGUAL', 'PROXIMO'])).sum() / len(results_df) * 100)
        if 'unit_type_match' in results_df.columns:
            scores.append((results_df['unit_type_match'] == 'SIM').sum() / len(results_df) * 100)
        
        if scores:
            avg_score = sum(scores) / len(scores)
            print(f"\n  SCORE GERAL (Metricas Individuais): {avg_score:.1f}%", end="")
            if avg_score >= 60:
                print(" [BOM - Pronto para A/B test]")
            elif avg_score >= 40:
                print(" [MODERADO - Precisa melhorar]")
            else:
                print(" [RUIM - Nao colocar em producao]")
            print(" [MODERADO - Precisa melhorar]")
        else:
            print(" [RUIM - Nao colocar em producao]")
    
    print("\nPROXIMOS PASSOS:")
    print("  1. Revisar resultados do checklist acima")
    print("  2. Se necessario, ajustar hiperparametros e retreinar")
    print("  3. Validar com mais sessoes de teste")
    print("  4. Apresentar resultados para stakeholders")
    print("  5. Considerar deploy em producao (A/B test)")


def main():
    parser = argparse.ArgumentParser(
        description='Analise de recomendacoes de modelos sequenciais'
    )
    parser.add_argument('--model_path', type=str, required=True)
    parser.add_argument('--features_path', type=str, required=True)
    parser.add_argument('--test_data_path', type=str, required=True)
    parser.add_argument('--num_sessions', type=int, default=5)
    parser.add_argument('--top_k', type=int, default=10)
    parser.add_argument('--output_dir', type=str, default=None)
    parser.add_argument('--no_viz', action='store_true')
    
    args = parser.parse_args()
    
    print_section_header("ANALISE DE RECOMENDACOES", char="=")
    print(f"\nModelo: {args.model_path}")
    print(f"Features: {args.features_path}")
    print(f"Test Data: {args.test_data_path}")
    print(f"Sessoes a analisar: {args.num_sessions}")
    print(f"Top-K: {args.top_k}")
    
    try:
        print_section_header("CARREGANDO MODELO")
        explorer = ModelExplorer(args.model_path)
        print("Modelo carregado com sucesso!")
        print(f"Total de itens: {explorer.dataset.item_num:,}")
        
        print_section_header("CARREGANDO FEATURES")
        explorer.load_item_features(args.features_path)
        print("Features carregadas com sucesso!")
        print(f"Total de anuncios: {len(explorer.item_features):,}")
        
        print_section_header("CARREGANDO DADOS DE TESTE")
        test_df = pd.read_csv(args.test_data_path, sep='\t')
        print("Dados de teste carregados com sucesso!")
        print(f"Total de interacoes: {len(test_df):,}")
        print(f"Colunas: {test_df.columns.tolist()}")
        
        print_section_header("ANALISE DE SESSAO EXEMPLO")
        valid_sessions = test_df.groupby('session_id:token').filter(lambda x: len(x) >= 3)
        
        # Selecionar sessão aleatória para visualização
        unique_sessions = valid_sessions['session_id:token'].unique()
        random_session_id = np.random.choice(unique_sessions)
        
        first_session_data = test_df[
            test_df['session_id:token'] == random_session_id
        ].sort_values('timestamp:float')
        first_session_items = first_session_data['item_id:token'].tolist()[:5]
        
        print(f"Sessao selecionada aleatoriamente para visualizacao: {random_session_id}")

        analyze_single_session(
            explorer,
            first_session_items,
            random_session_id,
            args.top_k
        )
        
        results_df = analyze_multiple_sessions(
            explorer,
            test_df,
            args.num_sessions,
            top_k=5
        )
        
        if not args.no_viz:
            output_dir = Path(args.output_dir) if args.output_dir else None
            print(f"\nGerando visualizacoes...")
            print(f"  Output dir: {output_dir}")
            print(f"  Sessao exemplo: {first_session_items}")
            create_visualizations(
                explorer,
                first_session_items,
                args.top_k,
                output_dir,
                results_df  # Passar results_df para gráficos agregados
            )
        
        print_final_summary(results_df)
        
        if args.output_dir:
            output_dir = Path(args.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            results_path = output_dir / 'analysis_results.csv'
            results_df.to_csv(results_path, index=False)
            print(f"\nResultados salvos em: {results_path}")
        
        print_section_header("ANALISE CONCLUIDA", char="=")
    
    except Exception as e:
        print(f"\nERRO: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
